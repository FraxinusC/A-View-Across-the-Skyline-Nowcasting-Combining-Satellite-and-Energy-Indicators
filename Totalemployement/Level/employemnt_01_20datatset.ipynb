{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from rasterio.enums import Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the data\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Applying the specified transformations\n",
    "    df['Time'] = df['Year'].apply(lambda x: datetime.datetime(x, 1, 1))\n",
    "\n",
    "    # Log transformation \n",
    "    cols_to_log_transform = ['Total Employment','GDP', 'Population', 'Personalincome', 'Percapitapersonalincome', 'econs', 'aland', 'awater','shape_area','shape_leng','Natural Gas Delivered to Consumers in California (Including Vehicle Fuel)  Million Cubic Feet']\n",
    "    df[cols_to_log_transform] = df[cols_to_log_transform].apply(np.log)\n",
    "\n",
    "    df.sort_values(by=['GeoFIPS', 'Time'], inplace=True)\n",
    "\n",
    "    df_cleaned = df.copy()\n",
    "\n",
    "    # Displaying the first few rows of the processed data\n",
    "    df_cleaned.head()\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EconomicDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, economic_features, img_size, img_augmented_size, scale_factor=0.6, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.economic_features = economic_features\n",
    "        self.img_size = img_size\n",
    "        self.img_augmented_size = img_augmented_size\n",
    "        self.transform = transform\n",
    "        self.years = dataframe['Year']  \n",
    "        self.geo_fips = dataframe['GeoFIPS']\n",
    "        self.scale_factor = scale_factor  \n",
    "\n",
    "    def read_and_resize_image(self, image_path):\n",
    "        with rasterio.open(image_path) as src:\n",
    "            data = src.read(\n",
    "                out_shape=(\n",
    "                    src.count,\n",
    "                    int(src.height * self.scale_factor),\n",
    "                    int(src.width * self.scale_factor)\n",
    "                ),\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "            data = data.astype('float32') \n",
    "            data[np.isnan(data)] = 0  \n",
    "            return data\n",
    "\n",
    "    def random_transform(self, image):\n",
    "        image = torch.from_numpy(image).float()\n",
    "        image = F.interpolate(image.unsqueeze(0), size=(self.img_size, self.img_size), mode='bilinear', align_corners=False).squeeze(0)\n",
    "        return torch.clamp(image, 0, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.dataframe.iloc[idx]['ImagePath'])\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(img_path) as src:\n",
    "                image = src.read().astype('float32')\n",
    "                image[np.isnan(image)] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Skipped corrupted image: {img_path}. Reason: {e}\")\n",
    "            return None  \n",
    "\n",
    "        image = self.random_transform(image)\n",
    "        economic_features = self.economic_features[idx].float()\n",
    "        label = self.dataframe.iloc[idx]['Total Employment']\n",
    "        year = self.years.iloc[idx]\n",
    "        geo_fips = self.geo_fips.iloc[idx]\n",
    "        return image, economic_features, label, year, geo_fips\n",
    "def safe_collate(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None  \n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset creation\n",
    "def create_datasets(df_cleaned, img_size, img_augmented_size):\n",
    "    # group by 'GeoFIPS' and split into train, validation, and test sets\n",
    "    grouped = df_cleaned.groupby('GeoFIPS')\n",
    "    train_df_list = []\n",
    "    val_df_list = []\n",
    "    test_df_list = []\n",
    "\n",
    "    for _, group in grouped:\n",
    "        if len(group) >= 3:\n",
    "            train, temp = train_test_split(group, test_size=0.3, random_state=42)\n",
    "            val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "            train_df_list.append(train)\n",
    "            val_df_list.append(val)\n",
    "            test_df_list.append(test)\n",
    "        else:\n",
    "\n",
    "            train_df_list.append(group)  \n",
    "\n",
    "\n",
    "    train_df = pd.concat(train_df_list)\n",
    "    val_df = pd.concat(val_df_list)\n",
    "    test_df = pd.concat(test_df_list)\n",
    "    scaler = MinMaxScaler()\n",
    "    columns_to_scale = ['econs','Population', 'Personalincome', 'Percapitapersonalincome', 'aland', 'awater','shape_area','shape_leng','Natural Gas Delivered to Consumers in California (Including Vehicle Fuel)  Million Cubic Feet','intptlat','intptlon']\n",
    "    scaler.fit(train_df[columns_to_scale])\n",
    "\n",
    "    train_features = scaler.transform(train_df[columns_to_scale])\n",
    "    test_features = scaler.transform(test_df[columns_to_scale])\n",
    "    val_features = scaler.transform(val_df[columns_to_scale])\n",
    "\n",
    "    train_features_tensor = torch.tensor(train_features, dtype=torch.float32)\n",
    "    test_features_tensor = torch.tensor(test_features, dtype=torch.float32)\n",
    "    val_features_tensor = torch.tensor(val_features, dtype=torch.float32)\n",
    "\n",
    "    train_dataset = EconomicDataset(train_df, \"<train_image_path>\", train_features_tensor, img_size, img_augmented_size)\n",
    "    val_dataset = EconomicDataset(val_df, \"<validation_image_path>\", val_features_tensor, img_size, img_augmented_size)\n",
    "    test_dataset = EconomicDataset(test_df, \"<test_image_path>\", test_features_tensor, img_size, img_augmented_size)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_dataset(dataset, save_path):\n",
    "    processed_data = []\n",
    "    skipped = 0  \n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        sample = dataset[i]\n",
    "        if sample is None:\n",
    "            skipped += 1\n",
    "            continue  \n",
    "\n",
    "        image, econ_features, label, year, geo_fips = sample\n",
    "\n",
    "        if torch.isnan(econ_features).any():\n",
    "            econ_features[torch.isnan(econ_features)] = 0\n",
    "\n",
    "        processed_data.append((image, econ_features, label, year, geo_fips))\n",
    "\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(processed_data, f)\n",
    "\n",
    "    print(f\"Saved processed data to {save_path}\")\n",
    "    print(f\"Skipped {skipped} corrupted samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = preprocess_data(\"E://Nowcasting Code//Data//Label//employment.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 43/155 [02:30<18:34,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Skipped corrupted image: E:\\County_CA_21y_all\\06029_2001.tif. Reason: Read failed. See previous exception for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [07:36<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to employment01_20_test_dataset.pkl\n",
      "Skipped 1 corrupted samples.\n"
     ]
    }
   ],
   "source": [
    "# 创建数据集\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(df_cleaned, 512, 512)\n",
    "\n",
    "\n",
    "# 处理和保存数据集到新的文件夹\n",
    "#process_and_save_dataset(train_dataset, \"employment01_20_train_dataset.pkl\")\n",
    "#process_and_save_dataset(val_dataset, \"employment01_20_val_dataset.pkl\")\n",
    "process_and_save_dataset(test_dataset, \"employment01_20_test_dataset.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
